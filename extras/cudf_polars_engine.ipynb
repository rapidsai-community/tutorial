{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee31ce0-49be-4f82-ab61-4d7f830ddca7",
   "metadata": {
    "id": "3ee31ce0-49be-4f82-ab61-4d7f830ddca7"
   },
   "source": [
    "# Introduction to the Polars GPU Engine\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/rapidsai-community/tutorial/refs/heads/main/images/polars-benchmark-best-queries.png\" style=\"float: right; margin-left: 5px; width: 500px;\">\n",
    "\n",
    "Polars is a popular single machine DataFrame library powered by an OLAP Query Engine. Beginning in the v1.3 release, \n",
    "Polars can now leverage NVIDIA GPUs for even higher performance through its GPU engine (powered by RAPIDS cuDF).\n",
    "\n",
    "Designed to make processing 10-100+ GBs of data feel interactive with just a single GPU, this new engine is built \n",
    "directly into the Polars Lazy API – just pass `**engine=\"gpu\"` to the `collect` operation.\n",
    "\n",
    "The GPU engine fully utilizes the Polars optimizer to ensure efficient execution and minimal memory usage, is compatible \n",
    "with the ecosystem of tools built for Polars, and has graceful CPU fallback for unsupported queries.\n",
    "\n",
    "**Note:** The GPU engine is only be available in Python Polars.\n",
    "\n",
    "This notebook is a short introduction to the Polars GPU engine, powered by cuDF. If you want to learn more about the \n",
    "implementation details, check out the [GPU engine release blog](https://pola.rs/posts/gpu-engine-release/) by the Polars\n",
    "team. \n",
    "\n",
    "**Attribution:** This notebook was adapted from [the polars GPU engine demo](https://github.com/rapidsai-community/showcase/blob/main/accelerated_data_processing_examples/polars_gpu_engine_demo.ipynb) \n",
    "from the rapids community repo. \n",
    "\n",
    "## The Polars GPU Engine\n",
    "\n",
    "- If you are running this on Google Colab, you are all set. \n",
    "- If you follow the local install setup via conda, you are also set. \n",
    "- If you installed dependencies via pip, you will need to do: \n",
    "\n",
    "```bash\n",
    "pip install - U polars[gpu] --extra-index-url=https://pypi.nvidia.com\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda8c8e",
   "metadata": {},
   "source": [
    "## Data \n",
    "We'll be working with a sample (20%) of the dataset of [simulated financial transactions from Kaggle](https://www.kaggle.com/datasets/conorsully1/simulated-transactions)\n",
    "\n",
    "If you are running this locally, and you followed the steps in the [0.Welcome_and_Setup.ipynb](https://github.com/rapidsai-community/tutorial/blob/main/0.Welcome_and_Setup.ipynb) notebook, you should have the `/data` folder ready to go. \n",
    "\n",
    "### Google Colab Instructions\n",
    "\n",
    "In the next step we download a script that will allow you to get the data for this notebook session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f693562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# colab: uncomment next line to get the data setup script\n",
    "#! wget https://raw.githubusercontent.com/rapidsai-community/tutorial/refs/heads/main/data_setup.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdbf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab: uncomment next line to get the pageviews data set\n",
    "#! python data_setup.py --transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06582ce0-5db4-46e6-8ced-1e65f97e54b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06582ce0-5db4-46e6-8ced-1e65f97e54b1",
    "outputId": "2d1b4473-b69a-4dcb-cb29-312c579c9664"
   },
   "outputs": [],
   "source": [
    "# Verify that you are running with an NVIDIA GPU\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea333c53-6402-43d6-b196-91d7e199b315",
   "metadata": {
    "id": "ea333c53-6402-43d6-b196-91d7e199b315"
   },
   "source": [
    "To begin, let's use Polars to read the parquet file and look at the schema and first few rows.\n",
    "\n",
    "With this dataset, we expect to see some meaningful performance benefits using NVIDIA GPUs for computationally heavy \n",
    "queries and limited benefits for basic queries that are primarily bottlenecked by reading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8364ee-3db7-40ae-80bd-76572c4e41ff",
   "metadata": {
    "id": "eb8364ee-3db7-40ae-80bd-76572c4e41ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f58fd-3df5-44ee-9a59-67d5c5146b08",
   "metadata": {
    "id": "a04f58fd-3df5-44ee-9a59-67d5c5146b08",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions = pl.scan_parquet(\"../data/transactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b5f7f-612d-4ee3-ab6c-8539bc36a8a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "271b5f7f-612d-4ee3-ab6c-8539bc36a8a0",
    "outputId": "d5d58fce-8704-48b8-f986-d8fdbb1e7551",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions.collect_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b44c08-a229-41b3-8e22-59f03eee68fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "86b44c08-a229-41b3-8e22-59f03eee68fd",
    "outputId": "8e3bade3-71af-4cba-8a6d-101cf8c83b7b"
   },
   "outputs": [],
   "source": [
    "transactions.head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5da5a9-4ca5-473b-a99f-b5ef4711e70e",
   "metadata": {
    "id": "fa5da5a9-4ca5-473b-a99f-b5ef4711e70e"
   },
   "source": [
    "This dataset has a mix of data types (strings, dates, integers, and floats), some missing values, and it looks like the \n",
    "dates were actually parsed as strings. We'll need to handle that during some of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc44e41-191c-4cee-8d99-29a47d5f3b78",
   "metadata": {
    "id": "bfc44e41-191c-4cee-8d99-29a47d5f3b78"
   },
   "source": [
    "## Let's use GPUs: Total aggregate transaction amount\n",
    "\n",
    "With Polars, to calculate the total spending of all transactions we simply `sum` the `AMOUNT` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4960ea1-a1fd-4af9-a08b-2dc6210117af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "f4960ea1-a1fd-4af9-a08b-2dc6210117af",
    "outputId": "4f82827f-2f1a-4e81-f4f2-220ffcdc93ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions.select(pl.col(\"AMOUNT\").sum()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a8068-5e43-4188-b268-1358af945048",
   "metadata": {
    "id": "fd4a8068-5e43-4188-b268-1358af945048"
   },
   "source": [
    "Looks like we're handling a high total transaction volume. Let's run the same query on the GPU.\n",
    "\n",
    "To use a GPU, we just need to tell Polars to use the GPU engine when we call `collect` by passing `engine=\"gpu\"` as a parameter.\n",
    "\n",
    "\n",
    "```python\n",
    "transactions.select(pl.col(\"AMOUNT\").sum()).collect(engine=\"gpu\")\n",
    "```\n",
    "\n",
    "The default configuration is likely the right choice for most workloads, but sometimes we want more control. We can \n",
    "provide more detailed configuration options (such as which device to run on and a variety of other options) by passing a\n",
    "Polars `GPUEngine` object to the `engine` parameter instead.\n",
    "\n",
    "\n",
    "In this notebook, we'll use `pl.GPUEngine`. The default configuration has transparent CPU fallback for unsupported \n",
    "operations, so if we execute an unsupported query we don't get an error. To prove we're running on the GPU, we'll pass a\n",
    "configured engine object that will raise an error if we can't run the query.\n",
    "\n",
    "_If you're running with [jupyterlab-nvdashboard](https://developer.nvidia.com/blog/maximize-gpu-performance-with-near-real-time-usage-stats-on-nvdashboard-v0-10/) you should see the GPU Memory and Utilization tick up._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308471b8-1086-470c-ac32-95e8af55fc9a",
   "metadata": {
    "id": "308471b8-1086-470c-ac32-95e8af55fc9a"
   },
   "outputs": [],
   "source": [
    "gpu_engine = pl.GPUEngine(\n",
    "    device=0,  # This is the default\n",
    "    raise_on_fail=True,  # Fail loudly if we can't run on the GPU.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96dc10-65b0-4399-a09e-bf6e0c94438c",
   "metadata": {
    "id": "9b96dc10-65b0-4399-a09e-bf6e0c94438c"
   },
   "source": [
    "The very first collection on the GPU will take a couple of seconds. The GPU engine is lazy-loaded so that even if the \n",
    "necessary packages are installed, Polars' fast import times are not affected. Consequently, when we trigger GPU execution\n",
    "for the first time, we load a number of additional packages, and initialize GPU-specific data structures and contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c74e0-94b7-48e4-9921-fb2a17a252f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "986c74e0-94b7-48e4-9921-fb2a17a252f5",
    "outputId": "e8762f10-f4fa-465d-fea5-06230df0ba6f"
   },
   "outputs": [],
   "source": [
    "transactions.select(pl.col(\"AMOUNT\").sum()).collect(engine=gpu_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87175dd-e11c-4146-92ae-4afd3417071b",
   "metadata": {
    "id": "e87175dd-e11c-4146-92ae-4afd3417071b"
   },
   "source": [
    "We probably don't need a GPU for such a simple operation on this dataset. But when we start doing more complex analysis, \n",
    "the high-bandwidth memory and compute power of GPUs will make things much more interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30466c12-ab87-4800-9bbb-5207197bb444",
   "metadata": {
    "id": "30466c12-ab87-4800-9bbb-5207197bb444"
   },
   "source": [
    "## More Complex Queries\n",
    "\n",
    "While the data is synthetic, it's representative of the kinds of datasets that come up in financial services, retail/e-commerce,\n",
    "consumer internet, and other industries.\n",
    "\n",
    "With this data, we can see how using GPU-accelerated Polars provides significant productivity boosts by exploring common\n",
    "business questions\n",
    "\n",
    "## Which customers have the largest total transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac30d66-a58b-4b72-83d6-99c0646b9e3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "7ac30d66-a58b-4b72-83d6-99c0646b9e3c",
    "outputId": "00a7c90b-d229-4cc2-a684-9185bb5e3ba2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res_cpu = (\n",
    "    transactions.group_by(\"CUST_ID\")\n",
    "    .agg(pl.col(\"AMOUNT\").sum())\n",
    "    .sort(by=\"AMOUNT\", descending=True)\n",
    "    .head()\n",
    "    .collect()\n",
    ")\n",
    "res_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e8afc",
   "metadata": {},
   "source": [
    "Since the dataset is fairly small, the execution of the query takes only a few seconds, but let's see what we get \n",
    "by running the same query on a GPU. \n",
    "\n",
    "To achieve this, is as simple as passing the `gpu_engine` we set above in our `.collect()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67acfc-531f-49a2-8485-b665d33468a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "3c67acfc-531f-49a2-8485-b665d33468a7",
    "outputId": "6b38aab4-f071-4efa-fe28-746a3902090a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "res_gpu = (\n",
    "    transactions.group_by(\"CUST_ID\")\n",
    "    .agg(pl.col(\"AMOUNT\").sum())\n",
    "    .sort(by=\"AMOUNT\", descending=True)\n",
    "    .head()\n",
    "    .collect(engine=gpu_engine)\n",
    ")\n",
    "res_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2e276-6ed2-47f2-b968-85586896a854",
   "metadata": {
    "id": "3ec2e276-6ed2-47f2-b968-85586896a854"
   },
   "source": [
    "Great! We see a nice performance gain when using the GPU engine!\n",
    "\n",
    "**Exercise:** Find the average transaction amount for each expense type.\n",
    "\n",
    "<details>\n",
    "  <summary>Solution (click dropdown) </summary>\n",
    "  <p>\n",
    "\n",
    "```python\n",
    "# to run this type it in a code cell\n",
    "ex_res_gpu = (\n",
    "    transactions.group_by(\"EXP_TYPE\")\n",
    "    .agg(pl.col(\"AMOUNT\").mean())\n",
    "    .sort(by=\"AMOUNT\", descending=True)\n",
    "    .collect(engine=gpu_engine)\n",
    ")\n",
    "ex_res_gpu\n",
    "```\n",
    "  </p>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0380a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f185ac0",
   "metadata": {},
   "source": [
    "\n",
    "## What about Polars SQL? \n",
    "\n",
    "In addition to the Dataframe interface, Polars also has an SQL interface. We can also use this with the GPU engine, since Polars translates both the DataFrame and SQL interfaces into a query execution plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a25d0-f777-4bb9-9c74-e15690675938",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "5b9a25d0-f777-4bb9-9c74-e15690675938",
    "outputId": "5d2de432-9bf0-48dc-9837-d10fb0eb831b"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT CUST_ID, SUM(AMOUNT) as sum_amt\n",
    "FROM transactions\n",
    "GROUP BY CUST_ID\n",
    "ORDER BY sum_amt DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "%time pl.sql(query).collect()\n",
    "%time pl.sql(query).collect(engine=gpu_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9efa0-1c69-4039-8a7b-7a55cb1ecf78",
   "metadata": {
    "id": "27c9efa0-1c69-4039-8a7b-7a55cb1ecf78"
   },
   "source": [
    "## Which customers have the largest single transaction?\n",
    "\n",
    "Customer `CP2KXQSX9I` had the largest total transactions over time (on the full dataset), but they might not have the largest single transaction. Let's find the top customers by single transaction amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26080e3-9b35-45cc-8a7e-c78926467ae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "b26080e3-9b35-45cc-8a7e-c78926467ae8",
    "outputId": "44138b1a-fd93-4aab-ee14-3ca5a894c229"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    transactions.group_by(\"CUST_ID\")\n",
    "    .agg(pl.col(\"AMOUNT\").max().alias(\"max_amount\"))\n",
    "    .sort(by=\"max_amount\", descending=True)\n",
    "    .head()\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696b693-fb50-4336-b06e-ca137ffb8897",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "c696b693-fb50-4336-b06e-ca137ffb8897",
    "outputId": "f1ad7126-66f8-4da2-b5d7-7b72ab6652b8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    transactions.group_by(\"CUST_ID\")\n",
    "    .agg(pl.col(\"AMOUNT\").max().alias(\"max_amount\"))\n",
    "    .sort(by=\"max_amount\", descending=True)\n",
    "    .head()\n",
    "    .collect(engine=gpu_engine)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080def6-d4e5-408c-8c8b-83a0895b0c3b",
   "metadata": {
    "id": "7080def6-d4e5-408c-8c8b-83a0895b0c3b"
   },
   "source": [
    "Again, we see a nice speedup using the GPU engine.\n",
    "\n",
    "**Exercise:** Find the average transaction amount for each expense type.\n",
    "\n",
    "_Hints_:\n",
    "1. First, think about what columns you need to group by to get daily transactions\n",
    "   - You'll need YEAR, MONTH, and DAY columns\n",
    "   - Remember that these are separate columns in the dataset\n",
    "\n",
    "2. For each day, we want to know:\n",
    "   - How many transactions occurred (len)\n",
    "   - The average transaction amount (mean)\n",
    "\n",
    "3. The aggregation should include:\n",
    "   - A count of all transactions\n",
    "   - The mean of the AMOUNT column\n",
    "   - Use .alias() to give meaningful names to the results\n",
    "\n",
    "4. After getting the results:\n",
    "   - Sort by transaction count in descending order\n",
    "   - Take only the top 10 busiest days\n",
    "\n",
    "<details>\n",
    "  <summary>Solution (click dropdown) </summary>\n",
    "  <p>\n",
    "\n",
    "```python\n",
    "# to run this type it in a code cell\n",
    "active_days_gpu = (\n",
    "    transactions.group_by([\"YEAR\", \"MONTH\", \"DAY\"])\n",
    "    .agg([\n",
    "        pl.len().alias(\"transaction_count\"),\n",
    "        pl.col(\"AMOUNT\").mean().alias(\"avg_amount\")\n",
    "    ])\n",
    "    .sort(by=\"transaction_count\", descending=True)\n",
    "    .head(10)\n",
    "    .collect(engine=gpu_engine)\n",
    ")\n",
    "active_days_gpu\n",
    "```\n",
    "  </p>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f33dad-b5f3-446d-a63e-95d907ab1cc8",
   "metadata": {
    "id": "d0f33dad-b5f3-446d-a63e-95d907ab1cc8"
   },
   "source": [
    "## Investigating a specific customer\n",
    "\n",
    "Let's explore the transactions of a single customer now. What was the largest transaction for customer `CIP0I11MG2`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e08be-5e30-41fa-a344-e2eb46e0085c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "048e08be-5e30-41fa-a344-e2eb46e0085c",
    "outputId": "b9559089-e7dc-4c08-d4bf-cca9bba5ff5d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    transactions.filter(pl.col(\"CUST_ID\") == \"CIP0I11MG2\")\n",
    "    .select(pl.col(\"AMOUNT\").max())\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a01a3d-f400-4439-b30b-09860439058a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "95a01a3d-f400-4439-b30b-09860439058a",
    "outputId": "feac9e75-feb0-4c97-90f9-6fad6a500093"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    transactions.filter(pl.col(\"CUST_ID\") == \"CIP0I11MG2\")\n",
    "    .select(pl.col(\"AMOUNT\").max())\n",
    "    .collect(engine=gpu_engine)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b01b0-13ec-4dcc-bd8e-26f193a54d21",
   "metadata": {
    "id": "fc6b01b0-13ec-4dcc-bd8e-26f193a54d21"
   },
   "source": [
    "### Why was performance using the CPU and GPU engines similar for this query?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a705fe-bb1e-440e-ad5a-829e68971298",
   "metadata": {
    "id": "b1a705fe-bb1e-440e-ad5a-829e68971298"
   },
   "source": [
    "What we've seen so far is that, for many common queries, we see significant performance increases when we use the GPU. \n",
    "But for this last one, things were more similar.\n",
    "\n",
    "Using Polars on a GPU isn't always a surefire winner in terms of speed when compared to Polars on a CPU. For simple queries\n",
    "that aren't computationally heavy, like the last query, we're often limited by the speed that we can read results from disk.\n",
    "\n",
    "Let's confirm this by profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acb8c5-4965-4b3d-bda6-cc484bae765a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "85acb8c5-4965-4b3d-bda6-cc484bae765a",
    "outputId": "5f610f40-4e70-47aa-fed9-c51a686850fb"
   },
   "outputs": [],
   "source": [
    "res, prof = (\n",
    "    transactions.filter(pl.col(\"CUST_ID\") == \"CIP0I11MG2\")\n",
    "    .select(pl.col(\"AMOUNT\").max())\n",
    "    .profile()\n",
    ")\n",
    "\n",
    "prof.with_columns(\n",
    "    ((pl.col(\"end\") - pl.col(\"start\")) / pl.col(\"end\").max() * 100).alias(\n",
    "        \"pct_time_spent\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ecf53-726a-467b-9493-c86cfab66e74",
   "metadata": {
    "id": "920ecf53-726a-467b-9493-c86cfab66e74"
   },
   "source": [
    "We spent 99.9%+ of the time just reading the data. Polars can use the GPU-accelerated Parquet reader to read this data, but ultimately when we're **IO bound** like this, there's less opportunity for GPU-acceleration.\n",
    "\n",
    "Let's try an even more computationally intense query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967525b-00da-488f-beba-6c14b74371de",
   "metadata": {
    "id": "3967525b-00da-488f-beba-6c14b74371de"
   },
   "source": [
    "## What's the per-month transaction amount for each category over time?\n",
    "\n",
    "For this query, we'll group and sort down to the individual month, which takes more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ca24a-abfd-4652-afe6-2d709f07d038",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c40ca24a-abfd-4652-afe6-2d709f07d038",
    "outputId": "beaca9d7-4d27-4330-a179-2f4511285c66"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res = (\n",
    "    transactions.group_by([\"EXP_TYPE\", \"YEAR\", \"MONTH\"])\n",
    "    .agg(pl.mean(\"AMOUNT\"))\n",
    "    .sort([\"EXP_TYPE\", \"YEAR\", \"MONTH\"])\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4810ebe-41b1-46f3-b3a6-9b4ffd9ad4f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4810ebe-41b1-46f3-b3a6-9b4ffd9ad4f3",
    "outputId": "746d93b6-9069-4175-d2cf-fcf201c28614"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res = (\n",
    "    transactions.group_by([\"EXP_TYPE\", \"YEAR\", \"MONTH\"])\n",
    "    .agg(pl.mean(\"AMOUNT\"))\n",
    "    .sort([\"EXP_TYPE\", \"YEAR\", \"MONTH\"])\n",
    "    .collect(engine=gpu_engine)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c9e6e-de8f-4b62-8799-e39dfc9ce61e",
   "metadata": {
    "id": "9f5c9e6e-de8f-4b62-8799-e39dfc9ce61e"
   },
   "source": [
    "Again, since this query does more work we see strong performance benefits on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1117ca-8667-49d7-a97e-1e01d9b2aa4b",
   "metadata": {
    "id": "0f1117ca-8667-49d7-a97e-1e01d9b2aa4b"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "With the new Polars GPU engine powered by cuDF, you can potentially achieve significant performance gains and lower costs\n",
    "for workflows processing 10-100+ GB of data.\n",
    "\n",
    "Key takeaways from this notebook:\n",
    "- The Polars GPU engine seamlessly integrates with cuDF to accelerate DataFrame operations\n",
    "- For IO-bound operations like reading data, GPU acceleration benefits are limited  \n",
    "- Computationally intensive operations like grouping and sorting show significant speedups on GPU\n",
    "- Switching between CPU and GPU engines requires minimal code changes - just add `engine=gpu_engine`\n",
    "\n",
    "To learn more, we encourage you to visit the [Polars GPU support documentation](https://docs.rapids.ai/api/cudf/stable/cudf_polars/) \n",
    "or visit [rapids.ai/cudf-polars](rapids.ai/cudf-polars).\n",
    "\n",
    "In the next notebook, we will learn about the accelerating machine learning workflows with cuML:\n",
    "\n",
    "[Next Notebook: 4 Intro to cuML →](https://colab.research.google.com/github/rapidsai-community/tutorial/blob/main/4.Intro_to_cuML.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
